{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models import resnet\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomResizedCrop, Resize, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.nn import CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate segmentation masks for 17k images\n",
    "\n",
    "image_folder = \"train/train/images/\"\n",
    "xml_folder = \"train/train/annotations/\"\n",
    "\n",
    "output_folder = \"train/train/segmentation_masks/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    objects = []\n",
    "    for obj in root.findall('object'):\n",
    "        obj_name = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text)\n",
    "        ymin = float(bbox.find('ymin').text)\n",
    "        xmax = float(bbox.find('xmax').text)\n",
    "        ymax = float(bbox.find('ymax').text)\n",
    "        objects.append((obj_name, (xmin, ymin, xmax, ymax)))\n",
    "    return objects\n",
    "\n",
    "\n",
    "def generate_segmentation_mask(image_size, objects):\n",
    "    mask = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)  # Initialize mask with 3 channels (RGB)\n",
    "\n",
    "    # Define colors for different classes\n",
    "    colors = {}\n",
    "    for obj_name, _ in objects:\n",
    "        if obj_name not in colors:\n",
    "            colors[obj_name] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))  # Generate random color for each class\n",
    "\n",
    "    # Assign colors to segmented regions\n",
    "    for obj_name, (xmin, ymin, xmax, ymax) in objects:\n",
    "        color = colors[obj_name]\n",
    "        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "        mask[ymin:ymax, xmin:xmax] = color  # Set pixels inside bounding box to color\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "# Process each image and its corresponding XML annotation\n",
    "for filename in tqdm(os.listdir(image_folder), desc=\"Processing Images\"):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        xml_path = os.path.join(xml_folder, filename.replace(\".jpg\", \".xml\"))\n",
    "\n",
    "        # Check if corresponding XML file exists\n",
    "        if os.path.exists(xml_path):\n",
    "            objects = parse_xml(xml_path)\n",
    "\n",
    "            # Read image\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Generate segmentation mask\n",
    "            mask = generate_segmentation_mask(image.shape[:2], objects)\n",
    "\n",
    "            mask = cv2.resize(mask, (256,256))\n",
    "\n",
    "            # Save segmentation mask\n",
    "            mask_filename = os.path.join(output_folder, filename.replace(\".jpg\", \".jpg\"))\n",
    "            cv2.imwrite(mask_filename, mask)\n",
    "        else:\n",
    "            print(f\"XML annotation not found for {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masks png to jpg\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Set the path to the folders containing the images.\n",
    "truth_path = \"train/train/ground_truth\"\n",
    "truth_jpg_path = \"train/train/ground_truth_jpg\"\n",
    "images_path = \"train/train/images\"\n",
    "real_path = \"train/train/true_real_images\"\n",
    "\n",
    "def convert_to_jpg(truth_path, truth_jpg_path):\n",
    "    # Open the image\n",
    "    img = Image.open(truth_path)\n",
    "    # Convert to RGB if it's not already\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    # Get the filename without extension\n",
    "    filename = os.path.splitext(os.path.basename(truth_path))[0]\n",
    "    # Save as JPEG\n",
    "    img.save(os.path.join(truth_jpg_path, filename + \".jpg\"), \"JPEG\")\n",
    "    print(f\"Converted {filename} to JPEG\")\n",
    "\n",
    "# Convert PNG images to JPEG\n",
    "for filename in os.listdir(truth_path):\n",
    "    if filename.endswith(\".png\"):\n",
    "        convert_to_jpg(os.path.join(truth_path, filename), truth_jpg_path)\n",
    "\n",
    "# Get a list of the files in each folder.\n",
    "truth_files = os.listdir(truth_jpg_path)\n",
    "images_files = os.listdir(images_path)\n",
    "\n",
    "# Create a list of the images that match the name of images in both folders.\n",
    "matching_images = []\n",
    "for file in truth_files:\n",
    "    if file in images_files:\n",
    "        matching_images.append(file)\n",
    "\n",
    "# Extract the images from folder1 and save them to folder2.\n",
    "for image in matching_images:\n",
    "    image_path = os.path.join(images_path, image)\n",
    "    new_image_path = os.path.join(real_path, image)\n",
    "    shutil.copy(image_path, new_image_path)\n",
    "\n",
    "print(\"Processing & extraction complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize image dimensions\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:\\\\users\\\\rpoje\\\\appdata\\\\local\\\\packages\\\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\\\localcache\\\\local-packages\\\\python310\\\\site-packages')\n",
    "\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"train/train\"\n",
    "output_dir = \"train/train/normalized\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to crop and resize an image\n",
    "def process_image(image_path, output_path, width, height):\n",
    "    try:\n",
    "        # Load the image\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image loaded successfully\n",
    "        if img is not None:\n",
    "            # Crop and resize the image\n",
    "            cropped_img = cv2.resize(img, (width, height))\n",
    "\n",
    "            # Create intermediate directories if they don't exist\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "            # Save the processed image to the output directory\n",
    "            cv2.imwrite(output_path, cropped_img)\n",
    "        else:\n",
    "            raise Exception(\"Error loading the image\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        # Delete the problematic image\n",
    "        os.remove(image_path)\n",
    "\n",
    "# Function to process images in subdirectories\n",
    "def process_subdirectory(input_subdir, output_subdir, width, height):\n",
    "    for root, _, files in os.walk(input_subdir):\n",
    "        for filename in files:\n",
    "            input_path = os.path.join(root, filename)\n",
    "            rel_path = os.path.relpath(input_path, input_subdir)\n",
    "            output_path = os.path.join(output_subdir, rel_path)\n",
    "            process_image(input_path, output_path, width, height)\n",
    "        print(\"done-1\")\n",
    "\n",
    "\n",
    "train_input_dir = os.path.join(input_dir, \"images\")\n",
    "train_output_dir = os.path.join(output_dir, \"images\")\n",
    "mask_input_dir = os.path.join(input_dir, \"segmentation_masks\")\n",
    "mask_output_dir = os.path.join(output_dir, \"masks\")\n",
    "\n",
    "# Process original image data\n",
    "process_subdirectory(train_input_dir, train_output_dir, 256, 256)\n",
    "\n",
    "# Process mask data\n",
    "process_subdirectory(mask_input_dir, mask_output_dir, 256, 256)\n",
    "\n",
    "print(\"Image processing and error handling completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cascaded Atrous Layers\n",
    "\n",
    "class AtrousCascade(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256, atrous_rates=[6, 12, 18]):\n",
    "        super(AtrousCascade, self).__init__()\n",
    "\n",
    "        self.conv1x1_input = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.bn0 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #1x1 convolution\n",
    "        self.conv1x1_1 = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #three 3x3 convolutions\n",
    "        self.conv3x3_1 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=atrous_rates[0], dilation=atrous_rates[0])\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3x3_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=atrous_rates[1], dilation=atrous_rates[1])\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3x3_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=atrous_rates[2], dilation=atrous_rates[2])\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #final logits\n",
    "        self.conv1x1_final = nn.Conv2d(out_channels,out_channels,kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out0x0 = F.relu(self.bn0(self.conv1x1_input(x)))\n",
    "        out1x1 = F.relu(self.bn1(self.conv1x1_1(out0x0)))\n",
    "        out3x3_1 = F.relu(self.bn2(self.conv3x3_1(out1x1)))\n",
    "        out3x3_2 = F.relu(self.bn3(self.conv3x3_2(out3x3_1)))\n",
    "        out3x3_3 = F.relu(self.bn4(self.conv3x3_3(out3x3_2)))\n",
    "\n",
    "        # Final 1x1 convolution for logits\n",
    "        out = self.conv1x1_final(out3x3_3)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atrous Spatial Pyramid Pooling\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256, atrous_rates=[6, 12, 18]):\n",
    "        super(ASPP, self).__init__()\n",
    "\n",
    "        self.conv1x1_input = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.bn0 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #1x1 convolution\n",
    "        self.conv1x1_1 = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #three 3x3 convolutions\n",
    "        self.conv3x3_1 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=atrous_rates[0], dilation=atrous_rates[0])\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3x3_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=atrous_rates[1], dilation=atrous_rates[1])\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3x3_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=atrous_rates[2], dilation=atrous_rates[2])\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Concatenate the parallel layers\n",
    "        self.conv1x1_concat = nn.Conv2d(out_channels * 4, out_channels, kernel_size=1)\n",
    "        self.bn_concat = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        #final logits\n",
    "        self.conv1x1_final = nn.Conv2d(out_channels,out_channels,kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out0x0 = F.relu(self.bn0(self.conv1x1_input(x)))\n",
    "        out1x1 = F.relu(self.bn1(self.conv1x1_1(out0x0)))\n",
    "        out3x3_1 = F.relu(self.bn2(self.conv3x3_1(out0x0)))\n",
    "        out3x3_2 = F.relu(self.bn3(self.conv3x3_2(out0x0)))\n",
    "        out3x3_3 = F.relu(self.bn4(self.conv3x3_3(out0x0)))\n",
    "\n",
    "        out = torch.cat([out1x1, out3x3_1, out3x3_2, out3x3_3], dim=1)\n",
    "\n",
    "        out = F.relu(self.bn_concat(self.conv1x1_concat(out)))\n",
    "\n",
    "        # Final 1x1 convolution for logits\n",
    "        out = self.conv1x1_final(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepLabV3\n",
    "\n",
    "class DeepLabV3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DeepLabV3, self).__init__()\n",
    "        # Load pre-trained ResNet-101 backbone\n",
    "        resnet101 = resnet.resnet101(pretrained=True)\n",
    "        # Remove the fully connected layer AND the average pooling layer\n",
    "        self.backbone = nn.Sequential(*list(resnet101.children())[:-2])\n",
    "        #print(self.backbone)\n",
    "\n",
    "        # ASPP module\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "\n",
    "        # Upsampling layer\n",
    "        self.upsample = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Final convolution layer\n",
    "        self.conv_final = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone feature extraction\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        # ASPP module\n",
    "        x = self.aspp(x)\n",
    "\n",
    "        # Upsampling\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        # Final convolution\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training protocols\n",
    "\n",
    "# Learning rate policy function\n",
    "def poly_lr_scheduler(optimizer, init_lr, iter, max_iter, power=0.9):\n",
    "    lr = init_lr * ((1 - iter / max_iter) ** power)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer\n",
    "\n",
    "# Data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    RandomResizedCrop(513),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_folder = 'train/true_real_images'\n",
    "        self.mask_folder = 'train/ground_truth_jpg'\n",
    "\n",
    "        self.image_paths = sorted([os.path.join(self.root, self.image_folder, filename) for filename in os.listdir(os.path.join(self.root, self.image_folder))])\n",
    "        self.mask_paths = sorted([os.path.join(self.root, self.mask_folder, filename) for filename in os.listdir(os.path.join(self.root, self.mask_folder))])\n",
    "\n",
    "        print(\"Number of images:\", len(self.image_paths))\n",
    "        print(\"Number of masks:\", len(self.mask_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        mask = Image.open(self.mask_paths[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        #mask = mask.permute(2, 0, 1)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 2913\n",
      "Number of masks: 2913\n"
     ]
    }
   ],
   "source": [
    "# Dataset and DataLoader\n",
    "data_dir = 'train/'\n",
    "train_dataset = CustomDataset(root=data_dir,transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = DeepLabV3(num_classes=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dice loss\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Flatten the input and target tensors\n",
    "        input_flat = input.view(-1)\n",
    "        target_flat = target.view(-1)\n",
    "\n",
    "        # Calculate intersection and union\n",
    "        intersection = (input_flat * target_flat).sum()\n",
    "        union = input_flat.sum() + target_flat.sum()\n",
    "\n",
    "        # Calculate Dice coefficient\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        # Calculate Dice loss\n",
    "        dice_loss = 1 - dice\n",
    "        return dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n",
      "torch.Size([16, 21, 272, 272])\n",
      "torch.Size([16, 3, 513, 513]) torch.Size([16, 3, 513, 513])\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.007, momentum=0.9, weight_decay=0.9997)\n",
    "\n",
    "# Loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "max_iter = 30000 #30k mentioned in paper\n",
    "for epoch in range(1, max_iter + 1):\n",
    "    model.train()\n",
    "    optimizer = poly_lr_scheduler(optimizer, 0.007, epoch, max_iter)\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        print(images.shape,labels.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        print(outputs.shape)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Freeze batch normalization parameters\n",
    "for module in model.modules():\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "        module.eval()\n",
    "        print(module.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset2(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_folder = 'train/images'\n",
    "        self.mask_folder = 'train/segmentation_masks'\n",
    "\n",
    "        self.image_paths = sorted([os.path.join(self.root, self.image_folder, filename) for filename in os.listdir(os.path.join(self.root, self.image_folder))])\n",
    "        self.mask_paths = sorted([os.path.join(self.root, self.mask_folder, filename) for filename in os.listdir(os.path.join(self.root, self.mask_folder))])\n",
    "\n",
    "        print(\"Number of images:\", len(self.image_paths))\n",
    "        print(\"Number of masks:\", len(self.mask_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        mask = Image.open(self.mask_paths[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        #mask = mask.permute(2, 0, 1)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.9997)\n",
    "\n",
    "#Loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "max_iter = 30000 #30k mentioned in paper\n",
    "for epoch in range(1, max_iter + 1):\n",
    "    model.train()\n",
    "    optimizer = poly_lr_scheduler(optimizer, 0.007, epoch, max_iter)\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        print(images.shape,labels.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        print(outputs.shape)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Freeze batch normalization parameters\n",
    "for module in model.modules():\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "        module.eval()\n",
    "        print(module.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Validation loop example:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, masks in val_loader:\n",
    "        outputs = model(images)\n",
    "        # Evaluate your model's performance on the validation set'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
